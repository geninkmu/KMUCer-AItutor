import os
import streamlit as st
import pdfplumber
from pptx import Presentation
from docx import Document
import pandas as pd
from striprtf.striprtf import rtf_to_text
from openai import OpenAI, RateLimitError
import numpy as np
import sqlite3
import json
import time

# åˆå§‹åŒ– OpenAI API
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("å°šæœªè¨­å®š OPENAI_API_KEYã€‚è«‹åœ¨æœ¬æ©Ÿä»¥ç’°å¢ƒè®Šæ•¸æˆ–åœ¨éƒ¨ç½²å¹³å°çš„ Secrets è¨­å®šã€‚")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# åˆå§‹åŒ– SQLite
DB_PATH = "kmucer.db"
conn = sqlite3.connect(DB_PATH)
c = conn.cursor()
c.execute('''CREATE TABLE IF NOT EXISTS chunks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source TEXT,
                content TEXT,
                embedding TEXT
            )''')
conn.commit()

# è®€å– PDF
def read_pdf(file):
    text = ""
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            text += page.extract_text() or ""
    return text

# è®€å– PPTX
def read_pptx(file):
    text = ""
    prs = Presentation(file)
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text += shape.text + "\n"
    return text

# è®€å– DOCX
def read_docx(file):
    text = ""
    doc = Document(file)
    for para in doc.paragraphs:
        text += para.text + "\n"
    return text

# è®€å– TXT
def read_txt(file):
    return file.read().decode("utf-8")

# è®€å– CSV
def read_csv(file):
    try:
        df = pd.read_csv(file)
    except UnicodeDecodeError:
        file.seek(0)
        df = pd.read_csv(file, encoding="big5", errors="ignore")
    return df.to_string()

# è®€å– RTF
def read_rtf(file):
    raw_text = file.read().decode("utf-8", errors="ignore")
    return rtf_to_text(raw_text)

# è¨ˆç®— embedding (å«é™é€Ÿé‡è©¦)
def get_embedding(text):
    for attempt in range(3):  # æœ€å¤šé‡è©¦ 3 æ¬¡
        try:
            response = client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return np.array(response.data[0].embedding)
        except RateLimitError:
            st.warning(f"âš ï¸ API è¢«é™é€Ÿäº†ï¼Œæ­£åœ¨é‡è©¦ ({attempt+1}/3)...")
            time.sleep(5)
    st.error("âŒ é€™æ®µæ–‡å­—å› ç‚º API é™åˆ¶ç„¡æ³•å»ºç«‹ embeddingï¼Œå·²è·³éã€‚")
    return None

# å„²å­˜åˆ° SQLite
def save_chunk(source, content, embedding):
    if embedding is not None:
        c.execute("INSERT INTO chunks (source, content, embedding) VALUES (?, ?, ?)", 
                  (source, content, json.dumps(embedding.tolist())))
        conn.commit()

# å¾ SQLite å–æ‰€æœ‰ chunk
def load_chunks():
    c.execute("SELECT source, content, embedding FROM chunks")
    rows = c.fetchall()
    chunks = []
    for row in rows:
        source, content, emb_json = row
        emb = np.array(json.loads(emb_json))
        chunks.append((source, content, emb))
    return chunks

# ç›¸ä¼¼åº¦è¨ˆç®— (cosine similarity)
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# ---------------- App é–‹å§‹ ----------------

st.title("ğŸ“š KMUCer åŠ©æ•™ (è€å¸« / å­¸ç”Ÿæ¨¡å¼)")

# è¼¸å…¥è§’è‰²å¯†ç¢¼
role = st.sidebar.text_input("è¼¸å…¥è§’è‰²å¯†ç¢¼ (ç•™ç©º = å­¸ç”Ÿæ¨¡å¼)", type="password")

# è¨­å®šè€å¸«å¯†ç¢¼
TEACHER_PASSWORD = "KMU2025"

# æ¨¡å¼åˆ¤æ–·
if role == TEACHER_PASSWORD:
    mode = "teacher"
    st.sidebar.success("å·²é€²å…¥ï¼šè€å¸«æ¨¡å¼")
else:
    mode = "student"
    st.sidebar.info("ç›®å‰æ˜¯ï¼šå­¸ç”Ÿæ¨¡å¼")

# ---------------- è€å¸«æ¨¡å¼ ----------------
if mode == "teacher":
    menu = st.sidebar.radio("åŠŸèƒ½é¸å–®", ["ğŸ’¬ åŠ©æ•™å°è©±", "ğŸ§± å»ºç«‹çŸ¥è­˜åº«"])

    if menu == "ğŸ§± å»ºç«‹çŸ¥è­˜åº«":
        st.header("å»ºç«‹ / æ›´æ–°æ•™æçŸ¥è­˜åº«")
        uploaded_files = st.file_uploader(
            "ä¸Šå‚³æ•™ææª”æ¡ˆ (PDF, PPTX, DOCX, TXT, CSV, RTF)", 
            accept_multiple_files=True
        )
        if st.button("ğŸš€ å»ºç«‹ç´¢å¼•") and uploaded_files:
            for file in uploaded_files:
                if file.name.endswith(".pdf"):
                    text = read_pdf(file)
                elif file.name.endswith(".pptx"):
                    text = read_pptx(file)
                elif file.name.endswith(".docx"):
                    text = read_docx(file)
                elif file.name.endswith(".txt"):
                    text = read_txt(file)
                elif file.name.endswith(".csv"):
                    text = read_csv(file)
                elif file.name.endswith(".rtf"):
                    text = read_rtf(file)
                else:
                    text = ""

                # åˆ‡å‰²æ–‡å­—æˆ chunk (åŠ å¤§æ¸›å°‘ API è«‹æ±‚æ•¸)
                chunks = [text[i:i+1500] for i in range(0, len(text), 1500)]
                for chunk in chunks:
                    emb = get_embedding(chunk)
                    save_chunk(file.name, chunk, emb)
            st.success("ç´¢å¼•å»ºç«‹å®Œæˆï¼")

# ---------------- å­¸ç”Ÿæ¨¡å¼ & å°è©±åŠŸèƒ½ ----------------
st.header("å‘ KMUCer æå•")
query = st.text_input("è¼¸å…¥ä½ çš„å•é¡Œï¼š")

if st.button("é€å‡ºå•é¡Œ") and query:
    chunks = load_chunks()
    context_text = ""
    if chunks:
        query_emb = get_embedding(query)
        sims = [(cosine_similarity(query_emb, emb), source, content) for source, content, emb in chunks]
        sims = sorted(sims, key=lambda x: x[0], reverse=True)[:3]
        context_text = "\n".join([s[2] for s in sims])
    else:
        st.info("ğŸ“‚ æ•™æçŸ¥è­˜åº«ç›®å‰ç‚ºç©ºï¼Œå°‡åƒ…ä¾é å¤§æ¨¡å‹å›ç­”ã€‚")

    system_prompt = f"""ä½ æ˜¯ KMUCerï¼Œé«˜é›„é†«å­¸å¤§å­¸é†«è—¥æš¨æ‡‰ç”¨åŒ–å­¸ç³»çš„èª²ç¨‹åŠ©æ•™ã€‚
    ä½ æ˜¯ç¢©å£«ç­å­¸å§Šï¼Œé¢¨æ ¼ã€Œå°ˆæ¥­ + è¦ªåˆ‡ + æç¬‘ã€ã€‚

    ä½ æœ‰å…©ç¨®çŸ¥è­˜ä¾†æºï¼š
    1. æ•™æçŸ¥è­˜åº«ï¼ˆä»¥ä¸‹æä¾›çš„å…§å®¹ï¼‰ â†’ å„ªå…ˆä½¿ç”¨
    2. ä½ è‡ªå·±çš„å°ˆæ¥­çŸ¥è­˜ï¼ˆå¤§æ¨¡å‹æœ¬èº«ï¼‰ â†’ åœ¨æ•™ææ²’æœ‰æ¶µè“‹æ™‚è£œå……

    ä»¥ä¸‹æ˜¯æ•™æå…§å®¹ï¼ˆå¦‚æœç©ºç™½ä»£è¡¨æ²’æœ‰ç›¸é—œæ•™æï¼‰ï¼š
    {context_text}

    è«‹çµåˆé€™äº›çŸ¥è­˜ï¼Œå›ç­”å­¸ç”Ÿçš„å•é¡Œã€‚
    """

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query}
        ]
    )

    answer = completion.choices[0].message.content
    st.markdown("### ğŸ—¨ï¸ KMUCer å›ç­”")
    st.write(answer)

    if context_text:
        st.markdown("### ğŸ“ åƒè€ƒæ•™æ")
        st.write(context_text)
